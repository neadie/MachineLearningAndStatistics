{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center>Machine Learning and Statistics Tasks Assignment </center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Name : Sinead Frawley\n",
    "## ID : G00376349"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>*Task 1*</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This task is to write a function callled sqrt2 that calculates  and prints to the screen the square root of 2 to 100 decimal places. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Research on Calculation Method</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method taken to calculate sqaure root of two is the  **Newton Sqaure root method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newtonian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$0 = f(x_0) + f'(x_0)(x_1 -x_0)$$\n",
    "\n",
    "$$x_1 - x_0 = - \\frac{f(x_0)}{f'(x_0)}$$ \n",
    "\n",
    "$$x_1 = x_0 -\\frac{f(x_0)}{f'(x_0)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"*Newtonian optimization is one of the basic ideas in optimization where function to be optimized is evaluated at a random point. Afterwards, this point is shifted in the negative direction of gradient until convergence.*\"[[1]](https://medium.com/@sddkal/newton-square-root-method-in-python-270853e9185d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a = x^2$$\n",
    "\n",
    "For, \n",
    "$$f(x) = x^2 - a$$\n",
    "$$f'(x)=x^2 -a $$\n",
    "     \n",
    "$$f(x) = 2x$$\n",
    "\n",
    "$$\\frac{f(x)}{f'(x)} = \\frac{x^2 -a}{2x} = \\frac{x -\\frac{a}{x}}{2}$$\n",
    "\n",
    "Since,\n",
    "\n",
    "$$x_{n+1} - x_n = -\\frac{f(x_n)}{f'(x_n)}$$\n",
    "\n",
    "$$x_{n+1}   = x_n -\\frac{x_n - \\frac{a}{x_n}}{2}$$\n",
    "\n",
    "$$x_{n+1}   = \\frac{x_n - \\frac{a}{x_n}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classic algorithm that illustrates many of these concerns is “Newton’s” method to compute square\n",
    "roots $x =√a$ for $a > 0$, i.e. to solve $x^2 = a$. The algorithm starts with some guess x1 > 0 and\n",
    "computes the sequence of improved guesses [[2]](https://math.mit.edu/~stevenj/18.335/newton-sqrt.pdf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_{n+1} = \\frac{1}{2}(x_{n} + \\frac{a}{x_{n}})$$\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sqrt2( number_iters = 500):\n",
    "    a = float(2) # number to get square root of\n",
    "    for i in range(number_iters): # iteration number\n",
    "        a = 0.5 * (a + 2 / a) # update\n",
    "        \n",
    "    print(\"{:.100f}\".format(a))\n",
    "  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730949234300169337075203657150268554687500000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "sqrt2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code from above is based on the function newton_method in [[1]](https://medium.com/@sddkal/newton-square-root-method-in-python-270853e9185d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>*Task 2*</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Task is on The Chi-squared test for independence is a statistical hypothesis test like a t-test. It is used to analyse whether two categorical variables\n",
    "are independent. The Wikipedia article gives the table below as an example [[7]](https://en.wikipedia.org/wiki/Chi-squared_test), stating the Chi-squared value based on it is approximately 24.6. I used  scipy.stats\n",
    "to verify this value and calculated the associated p value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Research on Chi Sqaured Tests</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi-square test is often used to assess the significance (if any) of the differences among k different groups. The null and alternate hypotheses of the test, are generally written as:\n",
    "\n",
    "H<sub>0</sub>: There is no significant difference between two or more groups.\n",
    "\n",
    "H<sub>A</sub> There exists at least one significant difference between two or more groups.\n",
    "\n",
    "The chi-square test statistic, denoted $x^2$, is defined as the following:[[3]](https://aaronschlegel.me/chi-square-test-independence-contingency-tables.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^2=\\sum_{i=1}^r\\sum_{i=1}^k\\frac{(O_{ij} -E_{ij})^2}{E_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $Oi_{j}$ is the i-th observed frequency in the j-th group and $E_{ij}$ is the corresponding expected frequency. The expected frequency can be calculated using a common statistical analysis. The expected frequency, typically denoted $E_{cr}$, where c is the column index and r is the row index. Stated more formally, the expected frequency is defined as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E_{cr}= \\frac{(\\sum_{i=0}^{n_r}r_i)((\\sum_{i=0}^{n_c}c_i)}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where n is the total sample size and nc,nr are the number of cells in row and column, respectively. The expected frequency is calculated for each 'cell' in the given array."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of data using Chi Squared Test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the data in [[7]](https://en.wikipedia.org/wiki/Chi-squared_test) . I have created calulcation on chi sqaured test below\n",
    "\n",
    "\n",
    "The two hypotheses are.\n",
    "\n",
    "1. Area and type of worker are independent.\n",
    "2. Area and type of worker are not independent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White collar</th>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>95</td>\n",
       "      <td>349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue collar</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "      <td>151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Collar</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total</th>\n",
       "      <td>150</td>\n",
       "      <td>150</td>\n",
       "      <td>200</td>\n",
       "      <td>150</td>\n",
       "      <td>650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                A    B    C    D  Total\n",
       "White collar   90   60  104   95    349\n",
       "Blue collar    30   50   51   20    151\n",
       "No Collar      30   40   45   35    150\n",
       "Total         150  150  200  150    650"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "data = {'A':[90, 30, 30, 150], 'B':[60, 50, 40, 150], 'C':[104, 51, 45, 200],\n",
    "        'D':[95, 20, 35, 150], 'Total':[349, 151, 150, 650]}\n",
    "df = pd.DataFrame(data,index=['White collar', 'Blue collar', 'No Collar', 'Total'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White collar</th>\n",
       "      <td>90</td>\n",
       "      <td>60</td>\n",
       "      <td>104</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue collar</th>\n",
       "      <td>30</td>\n",
       "      <td>50</td>\n",
       "      <td>51</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Collar</th>\n",
       "      <td>30</td>\n",
       "      <td>40</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               A   B    C   D\n",
       "White collar  90  60  104  95\n",
       "Blue collar   30  50   51  20\n",
       "No Collar     30  40   45  35"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obs = df.iloc[0:3, 0:4]\n",
    "obs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Expected Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Calculate \"Expected Value\" for each entry:\n",
    "Multiply each row total by each column total and divide by the overall total:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White collar</th>\n",
       "      <td>80.54</td>\n",
       "      <td>80.54</td>\n",
       "      <td>107.38</td>\n",
       "      <td>80.54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue collar</th>\n",
       "      <td>34.85</td>\n",
       "      <td>34.85</td>\n",
       "      <td>46.46</td>\n",
       "      <td>34.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Collar</th>\n",
       "      <td>34.62</td>\n",
       "      <td>34.62</td>\n",
       "      <td>46.15</td>\n",
       "      <td>34.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  A      B       C      D\n",
       "White collar  80.54  80.54  107.38  80.54\n",
       "Blue collar   34.85  34.85   46.46  34.85\n",
       "No Collar     34.62  34.62   46.15  34.62"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_exp = df.copy()\n",
    "\n",
    "for i in range(3):\n",
    "    for j in range(4):\n",
    "        df_exp.iloc[i,j] = df_exp.iloc[-1,j]*df_exp.iloc[i,-1]/df_exp.iloc[-1,-1]\n",
    "        j += 1\n",
    "  \n",
    "        \n",
    "df_exp = df_exp.drop(['Total'], axis=1).drop(['Total'], axis=0)        \n",
    "df_exp.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Partial Chi-squared value Results Table\n",
    "Subtract expected from observed, square it, then divide by expected:\n",
    "In other words, use formula  $\\frac{(O-E)^2}{E}$ where\n",
    "\n",
    "- O = Observed (actual) value \n",
    "- E = Expected value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>White collar</th>\n",
       "      <td>1.111527</td>\n",
       "      <td>5.237602</td>\n",
       "      <td>0.106678</td>\n",
       "      <td>2.596723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Blue collar</th>\n",
       "      <td>0.673968</td>\n",
       "      <td>6.590083</td>\n",
       "      <td>0.443327</td>\n",
       "      <td>6.325183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>No Collar</th>\n",
       "      <td>0.615385</td>\n",
       "      <td>0.837607</td>\n",
       "      <td>0.028846</td>\n",
       "      <td>0.004274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     A         B         C         D\n",
       "White collar  1.111527  5.237602  0.106678  2.596723\n",
       "Blue collar   0.673968  6.590083  0.443327  6.325183\n",
       "No Collar     0.615385  0.837607  0.028846  0.004274"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_chi = (obs.subtract(df_exp)**2)/df_exp\n",
    "df_chi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now add up those calculated values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.57"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chi2_value = df_chi.sum().sum()\n",
    "chi2_value.round(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center> Python chi square program </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Chi2 Stat===\n",
      "24.5712028585826\n",
      "\n",
      "\n",
      "===Degrees of Freedom===\n",
      "6\n",
      "\n",
      "\n",
      "===P-Value===\n",
      "0.0004098425861096696\n",
      "\n",
      "\n",
      "===Contingency Table===\n",
      "[[ 80.53846154  80.53846154 107.38461538  80.53846154]\n",
      " [ 34.84615385  34.84615385  46.46153846  34.84615385]\n",
      " [ 34.61538462  34.61538462  46.15384615  34.61538462]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "\n",
    "import numpy as np\n",
    "obs = np.array([[90, 60, 104,95], [30, 50, 51,20],[30,40,45,35]])\n",
    "chi2_contingency(obs)\n",
    "\n",
    "\n",
    "chi2_stat, p_val, dof, ex = chi2_contingency(obs)\n",
    "print(\"===Chi2 Stat===\")\n",
    "print(chi2_stat)\n",
    "print(\"\\n\")\n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n",
    "print(\"===Contingency Table===\")\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'scipy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-a00cb6d508d3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcrit_ss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchi2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mppf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.95\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdof_ss\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'scipy' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.stats import chi2\n",
    "crit_ss = chi2.ppf(q=0.95, df=dof_ss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analytics of calculations "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <center>**Task 3**<center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Standard Deviation you can get a handle on whether your data are close to the average or they are spread out over a wide range. For example, if an teacher wants to determine if the grades in one of his/her class seem fair for all students, or if there is a great disparity, he/she can use standard deviation. To do that, he/she can find the average of the salaries in that department and then calculate the standard deviation. In general, a low standard deviation means that the data is very closely related to the average, thus very reliable and a high standard deviation means that there is a large variance between the data and the statistical average, thus not as reliable[[4]](https://towardsdatascience.com/using-standard-deviation-in-python-77872c32ba9b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population Standard Deviation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma = \\frac{\\sqrt{\\sum(X_i - \\mu)^2}}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$\\sigma$ = population standard deviation </center>\n",
    "<center>$\\sum$ = sum of </center>\n",
    "<center>$X_i$ = each value in the sample </center>\n",
    "<center>$\\mu$= population mean</center>\n",
    "<center>N= number of values in the sample</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This standard deviation equation **Numpy** [[5]](https://towardsdatascience.com/why-computing-standard-deviation-in-pandas-and-numpy-yields-different-results-5b475e02d112)uses by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Stanadard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data is collected  it is actually quite rare that we work with populations. It is more likely that we will be working with samples of populations rather than whole populations itself.thus better to use sample standard deviation equation . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma = \\frac{\\sqrt{\\sum(X_i - \\mu)^2}}{N - 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$\\sigma$ = population standard deviation </center>\n",
    "<center>$\\sum$ = sum of </center>\n",
    "<center>$X_i$ = each value in the sample </center>\n",
    "<center>$\\mu$= population mean</center>\n",
    "<center>N= number of values in the sample</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diference between population and sample strandard deviation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is in the denominator of the equation. In sample standard deviation its divided by N- 1 instead of only using N as when compute population standard deviation.\n",
    "The reason for this is that in statistics in order to get an unbiased estimator for population standard deviation when calculating it from the sample we should be using (N-1). This is called one degree of freedom, we subtract 1 in order to get an unbiased estimator.[[6]](https://towardsdatascience.com/why-computing-standard-deviation-in-pandas-and-numpy-yields-different-results-5b475e02d112)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So is sample standard devaition better to use ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " N-1 should be used  in order to get the unbiased estimator. And this is usually the case as mostly dealing with samples, not entire populations. This is why pandas default standard deviation is computed using one degree of freedom.\n",
    "This may, however, may not be always the case so be sure what your data is before you use one or the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code samples to prove the case for sample stardard deviation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####### Simulate population data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had created a dataset using normal distribtion , only contain x values to simplify things .It has  N = 1,000,000 points  and its the  is 0.0, and the standard deviation is 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "mu, sigma = 0, 1 # mean and standard deviation\n",
    "s = np.random.normal(mu, sigma, 1000000)\n",
    "count, bins, ignored = plt.hist(s, 30, density=True)\n",
    "plt.plot(bins, 1/(sigma * np.sqrt(2 * np.pi)) *np.exp( - (bins - mu)**2 / (2 * sigma**2) ),linewidth=2, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate population stardard deviation of the entire sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((s - np.mean(s))**2)/len(s))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dealing with a sample "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First create a subnet of the orginal sample 10 datapoints "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(s)\n",
    "a = s[0:9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((a - np.mean(a))**2)/len(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.sum((a - np.mean(a))**2)/(len(a) -1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Dataset of 100 data points "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sample of 100 data points\n",
    "b = s[0:99]\n",
    "#population standard deviation \n",
    "np.sqrt(np.sum((b - np.mean(b))**2)/len(b))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sample stardard deviation \n",
    "np.sqrt(np.sum((b - np.mean(b))**2)/(len(b) -1) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Analysis of results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use scikit-learn to apply k-means clustering to Fisher’s famous Iris data set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Clustering is an unsupervisedlearning method that allows us to group set of objects based on similar characteristics. In general, it can help you find meaningful structure among your data, group similar data together and discover underlying patterns.\n",
    "One of the most common clustering methods is K-means algorithm. The goal of this algorithm isto partition the data into set such that the total sum of squared distances from each point to the mean point of the cluster is minimized.[[6]](https://medium.com/@belen.sanchez27/predicting-iris-flower-species-with-k-means-clustering-in-python-f6e46806aaee)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K means works through the following iterative process:[[6]](https://medium.com/@belen.sanchez27/predicting-iris-flower-species-with-k-means-clustering-in-python-f6e46806aaee)\n",
    "1. Pick a value for k (the number of clusters to create)\n",
    "2. Initialize k ‘centroids’ (starting points) in your data\n",
    "3. Create your clusters. Assign each point to the nearest centroid.\n",
    "4. Make your clusters better. Move each centroid to the center of its cluster.\n",
    "5. Repeat steps 3–4 until your centroids converge."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Iris Dataset "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Iris Dataset consists of 50 samples from each of three species of Iris (Iris setosa, Iris virginica and Iris versicolor). It has four features from each sample: length and width of sepals and petals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris = datasets.load_iris()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define your target and predictors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = iris.data[:, :2]\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scatter plot of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[:,0], X[:,1], c=y, cmap='gist_rainbow')\n",
    "plt.xlabel('Spea1 Length', fontsize=18)\n",
    "plt.ylabel('Sepal Width', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now, let’s instantiate and fit our K means cluster model. We are going to use three clusters and a random state of 21."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "km = KMeans(n_clusters = 3,  random_state=21)\n",
    "km.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centers = km.cluster_centers_\n",
    "print(centers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Compare our original data versus our clustered results using the code below "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this will tell us to which cluster does the data observations belong.\n",
    "new_labels = km.labels_\n",
    "# Plot the identified clusters and compare with the answers\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16,8))\n",
    "axes[0].scatter(X[:, 0], X[:, 1], c=y, cmap='gist_rainbow',\n",
    "edgecolor='k', s=150)\n",
    "axes[1].scatter(X[:, 0], X[:, 1], c=new_labels, cmap='jet',\n",
    "edgecolor='k', s=150)\n",
    "axes[0].set_xlabel('Sepal length', fontsize=18)\n",
    "axes[0].set_ylabel('Sepal width', fontsize=18)\n",
    "axes[1].set_xlabel('Sepal length', fontsize=18)\n",
    "axes[1].set_ylabel('Sepal width', fontsize=18)\n",
    "axes[0].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n",
    "axes[1].tick_params(direction='in', length=10, width=5, colors='k', labelsize=20)\n",
    "axes[0].set_title('Actual', fontsize=18)\n",
    "axes[1].set_title('Predicted', fontsize=18)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is a list of the main advantages and disadvantages of this algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Advantages:\n",
    "- K-Means is simple and computationally efficient.\n",
    "- It is very intuitive and their results are easy to visualize.\n",
    "###### Disadvantages:\n",
    "- K-Means is highly scale dependent and is not suitable for data of varying shapes and densities.\n",
    "- Evaluating results is more subjective. It requires much more human evaluation than trusted metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sıddık Açıl, May 6, 2018,Newton Square Root Method in Python,https://medium.com/@sddkal/newton-square-root-method-in-python-270853e9185d\n",
    "\n",
    "2. S. G. Johnson, MIT Course 18.335,February 4, 2015,Square Roots via Newton’s Method,https://math.mit.edu/~stevenj/18.335/newton-sqrt.pdf\n",
    "\n",
    "3. Aaron Schlegel, Mon 17 August 2020,Chi-Square Test of Independence for R x C Contingency Tables,https://aaronschlegel.me/chi-square-test-independence-contingency-tables.html\n",
    "\n",
    "4. Reza Rajabi,Aug 15, 2019, Using Standard Deviation in Python, Mean, Standard deviation, and Error bar in Python,https://towardsdatascience.com/using-standard-deviation-in-python-77872c32ba9b\n",
    "\n",
    "\n",
    "5. Magdalena Konkiewicz,Apr 29 2020,Why computing standard deviation in pandas and NumPy yields different results?\n",
    "Curious? Let’s talk about statistics, populations, and samples…, https://towardsdatascience.com/why-computing-standard-deviation-in-pandas-and-numpy-yields-different-results-5b475e02d112\n",
    "\n",
    "6. Belen Sanchez,Oct 21, 2018,Predicting Iris Flower Specices With K-means Clustering in python, https://medium.com/@belen.sanchez27/predicting-iris-flower-species-with-k-means-clustering-in-python-f6e46806aaee\n",
    "\n",
    "7. Wikipedia contributors, Chi-squared test — Wikipedia, the free encyclopedia,2020, https://en.wikipedia.org/wiki/Chi-squared_test\n",
    "8. Brayton Hall, Aug 23,The Reasoning Behind Bessel’s Correction: n-1 And Why it’s Not Always a Correction,https://towardsdatascience.com/the-reasoning-behind-bessels-correction-n-1-eeea25ec9bc9?gi=e2f9b21b47e5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
