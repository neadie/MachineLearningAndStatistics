{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning and Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <center>Calculation Method</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method taken to calculate sqaure root of two is the  **Newton Sqaure root method**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Newtonian Optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$0 = f(x_0) + f'(x_0)(x_1 -x_0)$$\n",
    "\n",
    "$$x_1 - x_0 = - \\frac{f(x_0)}{f'(x_0)}$$ \n",
    "\n",
    "$$x_1 = x_0 -\\frac{f(x_0)}{f'(x_0)} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"*Newtonian optimization is one of the basic ideas in optimization where function to be optimized is evaluated at a random point. Afterwards, this point is shifted in the negative direction of gradient until convergence.*\"[[1]](https://medium.com/@sddkal/newton-square-root-method-in-python-270853e9185d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$a = x^2$$\n",
    "\n",
    "For, \n",
    "$$f(x) = x^2 - a$$\n",
    "$$f'(x)=x^2 -a $$\n",
    "     \n",
    "$$f(x) = 2x$$\n",
    "\n",
    "$$\\frac{f(x)}{f'(x)} = \\frac{x^2 -a}{2x} = \\frac{x -\\frac{a}{x}}{2}$$\n",
    "\n",
    "Since,\n",
    "\n",
    "$$x_{n+1} - x_n = -\\frac{f(x_n)}{f'(x_n)}$$\n",
    "\n",
    "$$x_{n+1}   = x_n -\\frac{x_n - \\frac{a}{x_n}}{2}$$\n",
    "\n",
    "$$x_{n+1}   = \\frac{x_n - \\frac{a}{x_n}}{2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A classic algorithm that illustrates many of these concerns is “Newton’s” method to compute square\n",
    "roots $x =√a$ for $a > 0$, i.e. to solve $x^2 = a$. The algorithm starts with some guess x1 > 0 and\n",
    "computes the sequence of improved guesses [[2]](https://math.mit.edu/~stevenj/18.335/newton-sqrt.pdf )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x_{n+1} = \\frac{1}{2}(x_{n} + \\frac{a}{x_{n}})$$\n",
    "."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sqrt2( number_iters = 500):\n",
    "    a = float(2) # number to get square root of\n",
    "    for i in range(number_iters): # iteration number\n",
    "        a = 0.5 * (a + 2 / a) # update\n",
    "        \n",
    "    print(\"{:.100f}\".format(a))\n",
    "  \n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.4142135623730949234300169337075203657150268554687500000000000000000000000000000000000000000000000000\n"
     ]
    }
   ],
   "source": [
    "sqrt2()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chi Sqaured Tests "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chi-square test is often used to assess the significance (if any) of the differences among k different groups. The null and alternate hypotheses of the test, are generally written as:\n",
    "\n",
    "H<sub>0</sub>: There is no significant difference between two or more groups.\n",
    "\n",
    "H<sub>A</sub> There exists at least one significant difference between two or more groups.\n",
    "\n",
    "The chi-square test statistic, denoted $x^2$, is defined as the following:[[3]](https://aaronschlegel.me/chi-square-test-independence-contingency-tables.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$x^2=\\sum_{i=1}^r\\sum_{i=1}^k\\frac{(O_{ij} -E_{ij})^2}{E_{ij}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where $Oi_{j}$ is the i-th observed frequency in the j-th group and $E_{ij}$ is the corresponding expected frequency. The expected frequency can be calculated using a common statistical analysis. The expected frequency, typically denoted $E_{cr}$, where c is the column index and r is the row index. Stated more formally, the expected frequency is defined as:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$E_{cr}= \\frac{(\\sum_{i=0}^{n_r}r_i)((\\sum_{i=0}^{n_c}c_i)}{n}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Where n is the total sample size and nc,nr are the number of cells in row and column, respectively. The expected frequency is calculated for each 'cell' in the given array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===Chi2 Stat===\n",
      "25.31053121097707\n",
      "\n",
      "\n",
      "===Degrees of Freedom===\n",
      "6\n",
      "\n",
      "\n",
      "===P-Value===\n",
      "0.0002990757107414016\n",
      "\n",
      "\n",
      "===Contingency Table===\n",
      "[[ 80.41474654  80.95084485 107.21966206  80.41474654]\n",
      " [ 35.02304147  35.25652842  46.69738863  35.02304147]\n",
      " [ 34.56221198  34.79262673  46.08294931  34.56221198]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from scipy.stats import chi2_contingency\n",
    "import numpy as np\n",
    "obs = np.array([[90, 60, 104,95], [30, 51, 51,20],[30,40,45,35]])\n",
    "chi2_contingency(obs)\n",
    "\n",
    "\n",
    "chi2_stat, p_val, dof, ex = chi2_contingency(obs)\n",
    "print(\"===Chi2 Stat===\")\n",
    "print(chi2_stat)\n",
    "print(\"\\n\")\n",
    "print(\"===Degrees of Freedom===\")\n",
    "print(dof)\n",
    "print(\"\\n\")\n",
    "print(\"===P-Value===\")\n",
    "print(p_val)\n",
    "print(\"\\n\")\n",
    "print(\"===Contingency Table===\")\n",
    "print(ex)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Standard Deviation you can get a handle on whether your data are close to the average or they are spread out over a wide range. For example, if an teacher wants to determine if the grades in one of his/her class seem fair for all students, or if there is a great disparity, he/she can use standard deviation. To do that, he/she can find the average of the salaries in that department and then calculate the standard deviation. In general, a low standard deviation means that the data is very closely related to the average, thus very reliable and a high standard deviation means that there is a large variance between the data and the statistical average, thus not as reliable[[4]](https://towardsdatascience.com/using-standard-deviation-in-python-77872c32ba9b)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Population Standard Deviation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma = \\frac{\\sqrt{\\sum(X_i - \\mu)^2}}{N}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$\\sigma$ = population standard deviation </center>\n",
    "<center>$\\sum$ = sum of </center>\n",
    "<center>$X_i$ = each value in the sample </center>\n",
    "<center>$\\mu$= population mean</center>\n",
    "<center>N= number of values in the sample</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This standard deviation equation **Numpy** [[5]](https://towardsdatascience.com/why-computing-standard-deviation-in-pandas-and-numpy-yields-different-results-5b475e02d112)uses by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample Stanadard Deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When data is collected  it is actually quite rare that we work with populations. It is more likely that we will be working with samples of populations rather than whole populations itself.thus better to use sample standard deviation equation . "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\\sigma = \\frac{\\sqrt{\\sum(X_i - \\mu)^2}}{N - 1}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>$\\sigma$ = population standard deviation </center>\n",
    "<center>$\\sum$ = sum of </center>\n",
    "<center>$X_i$ = each value in the sample </center>\n",
    "<center>$\\mu$= population mean</center>\n",
    "<center>N= number of values in the sample</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diference between population and sample strandard deviation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The difference is in the denominator of the equation. In sample standard deviation its divided by N- 1 instead of only using N as when compute population standard deviation.\n",
    "The reason for this is that in statistics in order to get an unbiased estimator for population standard deviation when calculating it from the sample we should be using (N-1). This is called one degree of freedom, we subtract 1 in order to get an unbiased estimator.[[6]](https://towardsdatascience.com/why-computing-standard-deviation-in-pandas-and-numpy-yields-different-results-5b475e02d112)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### So is sample standard devaition better to use ? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " N-1 should be used  in order to get the unbiased estimator. And this is usually the case as mostly dealing with samples, not entire populations. This is why pandas default standard deviation is computed using one degree of freedom.\n",
    "This may, however, may not be always the case so be sure what your data is before you use one or the other. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Code samples to prove the case for sample stardard deviation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>161</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>156</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>172</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   height  weight\n",
       "0     161      67\n",
       "1     156      65\n",
       "2     172      89"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame({'height' : [161, 156, 172], \n",
    "                   'weight': [67, 65, 89]})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.316656236958787"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.weight.std()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.873004286866728"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.std(df.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The degree in of freedom in NumPy to change this to unbiased estimator by using ddof parameter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13.316656236958787"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(df.weight,ddof=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Sıddık Açıl, May 6, 2018,Newton Square Root Method in Python,https://medium.com/@sddkal/newton-square-root-method-in-python-270853e9185d\n",
    "\n",
    "2. S. G. Johnson, MIT Course 18.335,February 4, 2015,Square Roots via Newton’s Method,https://math.mit.edu/~stevenj/18.335/newton-sqrt.pdf\n",
    "\n",
    "3. Aaron Schlegel, Mon 17 August 2020,Chi-Square Test of Independence for R x C Contingency Tables,https://aaronschlegel.me/chi-square-test-independence-contingency-tables.html\n",
    "\n",
    "4. Reza Rajabi,Aug 15, 2019, Using Standard Deviation in Python, Mean, Standard deviation, and Error bar in Python,https://towardsdatascience.com/using-standard-deviation-in-python-77872c32ba9b\n",
    "\n",
    "\n",
    "5. Magdalena Konkiewicz,Apr 29 2020,Why computing standard deviation in pandas and NumPy yields different results?\n",
    "Curious? Let’s talk about statistics, populations, and samples…, https://towardsdatascience.com/why-computing-standard-deviation-in-pandas-and-numpy-yields-different-results-5b475e02d112"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
